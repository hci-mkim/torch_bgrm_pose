{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cython\n",
    "!pip install opencv-python pillow pycocotools matplotlib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\min11\\Desktop\\coding\\torch_bgrm_pose\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import os\n",
    "from os.path import exists, join, basename, splitext\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as T\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "import cv2\n",
    "print(os.getcwd())\n",
    "\n",
    "# Download Model\n",
    "model = models.detection.keypointrcnn_resnet50_fpn(pretrained=True).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Transform video to image(per seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video to Image\n",
    "path = \"./img/1_input_video/\"\n",
    "file_list = os.listdir(path)\n",
    "print(\"{}\".format(file_list))\n",
    "\n",
    "def getFrame(sec):\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,image = vidcap.read()\n",
    "\n",
    "    if hasFrames:\n",
    "        h = 256\n",
    "        w = 256\n",
    "        resized_image = cv2.resize(image, (h, w)).astype(np.float32)\n",
    "        if count < 10:\n",
    "            cv2.imwrite(\"./img/2_input/\"+'0000'+str(count)+\".jpg\", resized_image)     # save frame as JPG file\n",
    "        elif count < 100:\n",
    "            cv2.imwrite(\"./img/2_input/\"+'000'+str(count)+\".jpg\", resized_image)     # save frame as JPG file\n",
    "        elif count < 1000:\n",
    "            cv2.imwrite(\"./img/2_input/\"+'00'+str(count)+\".jpg\", resized_image)     # save frame as JPG file\n",
    "        elif count < 10000:\n",
    "            cv2.imwrite(\"./img/2_input/\"+'0'+str(count)+\".jpg\", resized_image)     # save frame as JPG file\n",
    "\n",
    "    return hasFrames\n",
    "\n",
    "for file in file_list:\n",
    "    vidcap = cv2.VideoCapture(path+file)\n",
    "    sec = 0\n",
    "    frameRate = 1 #//it will capture image in each 1 second\n",
    "    count=1\n",
    "    success = getFrame(sec)\n",
    "\n",
    "    while success:\n",
    "        count = count + 1\n",
    "        sec = sec + frameRate\n",
    "        sec = round(sec, 2)\n",
    "        success = getFrame(sec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Background Subtraction(YOLACT++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\min11\\Desktop\\coding\\torch_bgrm_pose\\yolact\n",
      "Config not specified. Parsed yolact_resnet50_config from the file name.\n",
      "\n",
      "Loading model... Done.\n",
      "\n",
      "..\\img\\2_input\\10.jpg -> ../img/3_output_bg\\10.jpg\n",
      "..\\img\\2_input\\11.jpg -> ../img/3_output_bg\\11.jpg\n",
      "..\\img\\2_input\\12.jpg -> ../img/3_output_bg\\12.jpg\n",
      "..\\img\\2_input\\13.jpg -> ../img/3_output_bg\\13.jpg\n",
      "..\\img\\2_input\\19.jpg -> ../img/3_output_bg\\19.jpg\n",
      "..\\img\\2_input\\5.jpg -> ../img/3_output_bg\\5.jpg\n",
      "..\\img\\2_input\\6.jpg -> ../img/3_output_bg\\6.jpg\n",
      "..\\img\\2_input\\7.jpg -> ../img/3_output_bg\\7.jpg\n",
      "..\\img\\2_input\\8.jpg -> ../img/3_output_bg\\8.jpg\n",
      "..\\img\\2_input\\9.jpg -> ../img/3_output_bg\\9.jpg\n",
      "Done.\n",
      "C:\\Users\\min11\\Desktop\\coding\\torch_bgrm_pose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\min11\\Anaconda3\\lib\\site-packages\\torch\\jit\\_recursive.py:181: UserWarning: 'lat_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
      "  warnings.warn(\"'{}' was found in ScriptModule constants, \"\n",
      "C:\\Users\\min11\\Anaconda3\\lib\\site-packages\\torch\\jit\\_recursive.py:181: UserWarning: 'pred_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
      "  warnings.warn(\"'{}' was found in ScriptModule constants, \"\n",
      "C:\\Users\\min11\\Anaconda3\\lib\\site-packages\\torch\\jit\\_recursive.py:181: UserWarning: 'downsample_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
      "  warnings.warn(\"'{}' was found in ScriptModule constants, \"\n"
     ]
    }
   ],
   "source": [
    "%cd yolact\n",
    "!python eval.py --trained_model=weights/yolact_resnet50_54_800000.pth --score_threshold=0.15 --top_k=1 --images=\"../img/2_input\":\"../img/3_output_bg\"\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Skeleton Detection(Mask R-CNN Keypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.jpg', '11.jpg', '12.jpg', '13.jpg', '19.jpg', '5.jpg', '6.jpg', '7.jpg', '8.jpg', '9.jpg']\n"
     ]
    }
   ],
   "source": [
    "path = './img/3_output_bg/'\n",
    "file_list = os.listdir(path)\n",
    "print(\"{}\".format(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.jpg', '11.jpg', '12.jpg', '13.jpg', '19.jpg', '5.jpg', '6.jpg', '7.jpg', '8.jpg', '9.jpg']\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.95\n",
    "\n",
    "path = \"./img/3_output_bg/\"\n",
    "file_list = os.listdir(path)\n",
    "print(\"{}\".format(file_list))\n",
    "\n",
    "for file in file_list:\n",
    "\n",
    "    image = Image.open(\"./img/3_output_bg/\"+file)\n",
    "    \n",
    "    t = time.time()\n",
    "    # Image to Tensor\n",
    "    trf = T.Compose([\n",
    "        T.Resize(256),\n",
    "        T.ToTensor() \n",
    "        ])\n",
    "    input_img = trf(image) \n",
    "    out = model([input_img])[0]\n",
    "\n",
    "    codes = [\n",
    "        Path.MOVETO,\n",
    "        Path.LINETO,\n",
    "        Path.LINETO\n",
    "    ]\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "    ax.imshow(image)\n",
    "\n",
    "    for box, score, keypoints in zip(out['boxes'], out['scores'], out['keypoints']):\n",
    "        # 스코어가 95% 이상인 것만 사용\n",
    "        score = score.detach().numpy() # score(텐서)를 떼어내서 numpy배열로 바꾼다.\n",
    "\n",
    "        if score < THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        box = box.detach().numpy()\n",
    "        keypoints = keypoints.detach().numpy()[:, :2] # numpy array로 변환하고 2개의 값(x, y)만 저장\n",
    "\n",
    "        rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], linewidth=2, edgecolor='b', facecolor='none')\n",
    "        ax.add_patch(rect) # matplotlib에 patches를 사용하여 박스를 그려준다.\n",
    "\n",
    "        # 17 keypoints(표시할 점의 갯수를 조절가능)\n",
    "        for k in keypoints[5:13]:\n",
    "\n",
    "            circle = patches.Circle((k[0], k[1]), radius=2, facecolor='r')\n",
    "            ax.add_patch(circle)\n",
    "            \n",
    "            ax.text(keypoints[5][0],keypoints[5][1], '5', color='green')\n",
    "            ax.text(keypoints[6][0],keypoints[6][1], '6', color='yellow')\n",
    "            ax.text(keypoints[7][0],keypoints[7][1], '7', color='green')\n",
    "            ax.text(keypoints[8][0],keypoints[8][1], '8', color='yellow')\n",
    "            ax.text(keypoints[9][0],keypoints[9][1], '9', color='green')\n",
    "            ax.text(keypoints[10][0],keypoints[10][1], '10', color='yellow')\n",
    "            ax.text(keypoints[11][0],keypoints[11][1], '11', color='green')\n",
    "            ax.text(keypoints[12][0],keypoints[12][1], '12', color='yellow')\n",
    "\n",
    "            head = ((keypoints[3]+keypoints[4])/2)\n",
    "            ax.text(head[0],head[1], '3/4', color='yellow')\n",
    "\n",
    "            # Draw line\n",
    "            # 왼쪽어깨굴곡(6,8,12)\n",
    "            verts = [keypoints[8],keypoints[6],keypoints[12]]\n",
    "            path = Path(verts, codes)\n",
    "            line = patches.PathPatch(path, linewidth=2, facecolor='none', edgecolor='r')\n",
    "            ax.add_patch(line)\n",
    "\n",
    "\n",
    "            # 왼쪽팔꿈치굴곡(5,7,9)\n",
    "            verts = [keypoints[5],keypoints[7],keypoints[9]]\n",
    "            path = Path(verts, codes)\n",
    "            line = patches.PathPatch(path, linewidth=2, facecolor='none', edgecolor='y')\n",
    "            ax.add_patch(line)\n",
    "\n",
    "            # 오른쪽어깨굴곡(11,5,7)\n",
    "            verts = [keypoints[11],keypoints[5],keypoints[7]]\n",
    "            path = Path(verts, codes)\n",
    "            line = patches.PathPatch(path, linewidth=2, facecolor='none', edgecolor='y')\n",
    "            ax.add_patch(line)\n",
    "\n",
    "            # 오른쪽팔꿈치굴곡(6,8,10)\n",
    "            verts = [keypoints[6],keypoints[8],keypoints[10]]\n",
    "            path = Path(verts, codes)\n",
    "            line = patches.PathPatch(path, linewidth=2, facecolor='none', edgecolor='r')\n",
    "            ax.add_patch(line)\n",
    "\n",
    "            # 목 굴곡\n",
    "            verts = [((keypoints[3]+keypoints[4])/2),((keypoints[5]+keypoints[6])/2),((keypoints[11]+keypoints[12])/2)]\n",
    "            path = Path(verts, codes)\n",
    "            line = patches.PathPatch(path, linewidth=2, facecolor='none', edgecolor='g')\n",
    "            ax.add_patch(line)\n",
    "\n",
    "            # 허리 굴곡\n",
    "            verts = [((keypoints[5]+keypoints[6])/2), ((keypoints[11]+keypoints[12])/2), (((keypoints[11]+keypoints[12])/2)[0],((keypoints[5]+keypoints[6])/2)[1])]\n",
    "            path = Path(verts, codes)\n",
    "            line = patches.PathPatch(path, linewidth=1, facecolor='none', edgecolor='b')\n",
    "            ax.add_patch(line)\n",
    "            ax.set_axis_off()\n",
    "            fig.savefig('./img/4_output_kp/'+file, bbox_inches='tight')\n",
    "            \n",
    "    # 각도 계산\n",
    "    import math\n",
    "    def getAngle(a, b, c):\n",
    "        ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "        return abs(ang - 360) if ang > 180 else abs(ang) #+ 360 if ang < 0 else ang\n",
    "\n",
    "    left_sho_angle = (getAngle((keypoints[7]), (keypoints[5]), (keypoints[11])))\n",
    "    right_sho_angle = (getAngle((keypoints[8]), (keypoints[6]), (keypoints[12])))\n",
    "    \n",
    "    left_albow_angle = (getAngle((keypoints[5]), (keypoints[7]), (keypoints[9])))\n",
    "    right_albow_angle = (getAngle((keypoints[6]), (keypoints[8]), (keypoints[10])))\n",
    "\n",
    "    \n",
    "    neck_angle = getAngle(((keypoints[3]+keypoints[4])/2),((keypoints[5]+keypoints[6])/2),((keypoints[11]+keypoints[12])/2))\n",
    "    if neck_angle > 90 :\n",
    "        neck_angle = (180 - getAngle(((keypoints[3]+keypoints[4])/2), ((keypoints[5]+keypoints[6])/2), ((keypoints[11]+keypoints[12])/2)))/2\n",
    "    elif neck_angle >= 45:\n",
    "        neck_angle = neck_angle/15\n",
    "    elif neck_angle < 45:\n",
    "        neck_angle = neck_angle\n",
    "\n",
    "    trunk_angle = getAngle(((keypoints[5]+keypoints[6])/2), ((keypoints[11]+keypoints[12])/2),(((keypoints[11]+keypoints[12])/2)[0],((keypoints[5]+keypoints[6])/2)[1]))/2\n",
    "    print(\"작업명 : \"+file)\n",
    "    print(\"왼쪽 어깨 굴곡 각도       : \"+str(round(left_sho_angle, 2))+\" 도\")\n",
    "    print(\"왼쪽 팔꿈치 굴곡 각도     : \"+str(round(left_albow_angle, 2))+\" 도\")\n",
    "    print(\"오른쪽 어깨 굴곡 각도     : \"+str(round(right_sho_angle, 2))+\" 도\")\n",
    "    print(\"오른쪽 팔꿈치 굴곡 각도   : \"+str(round(right_albow_angle, 2))+\" 도\")\n",
    "    print(\"목 굴곡 각도              : \"+str(round(neck_angle, 2))+\" 도\")\n",
    "    print(\"허리 굴곡 각도            : \"+str(round(trunk_angle, 2))+\" 도\")\n",
    "\n",
    "\n",
    "    print('executed in %.3fs' % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
